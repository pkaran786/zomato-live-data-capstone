{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "092b6a4a-3b87-40cd-84cc-9d65ed6d1f04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import explode, col, regexp_replace, lit\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Flattened user data from JSON source with masked sensitive info\"\n",
    ")\n",
    "def users_bronze():\n",
    "    try:\n",
    "        # Read JSON data\n",
    "        df_users = spark.read.json(\n",
    "            \"/Volumes/dlt_manas/my_schema/delta_live_tables/Landing/live_data/users.json\"\n",
    "        )\n",
    "\n",
    "        # Explode rows\n",
    "        df_users_exploded = df_users.withColumn(\"user\", explode(col(\"rows\")))\n",
    "\n",
    "        # Select required columns\n",
    "        users_bronze = df_users_exploded.select(\n",
    "            col(\"user.id\").alias(\"id\"),\n",
    "            col(\"user.name\").alias(\"name\"),\n",
    "            col(\"user.username\").alias(\"username\"),\n",
    "            # Mask email: keep first 2 chars and domain\n",
    "            regexp_replace(col(\"user.email\"), r\"(^..)[^@]*(@.*$)\", r\"$1****$2\").alias(\"email\"),\n",
    "            # Mask phone: keep last 2 digits\n",
    "            regexp_replace(col(\"user.phone\"), r\".*(\\d{2})$\", r\"****$1\").alias(\"phone\"),\n",
    "            col(\"user.gender\").alias(\"gender\"),\n",
    "            col(\"user.food_preference\").alias(\"food_preference\"),\n",
    "            col(\"user.locality\").alias(\"locality\"),\n",
    "            col(\"user.address\").alias(\"address\"),\n",
    "            col(\"user.role\").alias(\"role\"),\n",
    "            col(\"user.is_active\").alias(\"is_active\"),\n",
    "            col(\"user.created_at\").alias(\"created_at\"),\n",
    "            col(\"user.updated_at\").alias(\"updated_at\")\n",
    "        )\n",
    "\n",
    "        return users_bronze\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log exception details in a separate DLT table\n",
    "        error_df = spark.createDataFrame(\n",
    "            [(str(e), \"users_bronze\", \"Possible dropped columns or schema mismatch\")],\n",
    "            [\"error_message\", \"table_name\", \"details\"]\n",
    "        )\n",
    "        dlt.create_streaming_table(\"exception_log\")\n",
    "        return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e366852-248b-4c00-998b-af3d3e515742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Flattened activity logs from JSON source\"\n",
    ")\n",
    "def raw_dataBronze():\n",
    "    # Read the raw JSON file\n",
    "    df = spark.read.json(\n",
    "        \"/Volumes/dlt_manas/my_schema/delta_live_tables/Landing/live_data/raw-data.json\"\n",
    "    )\n",
    "\n",
    "    # Explode the array column (replace 'data.activityLogs' with actual column if different)\n",
    "    df_exploded = df.withColumn(\n",
    "        \"activityLog\",\n",
    "        explode(col(\"data.activityLogs\"))\n",
    "    )\n",
    "\n",
    "    # Select and flatten the required fields\n",
    "    raw_data_bronze = df_exploded.select(\n",
    "        col(\"activityLog.details.amount\").alias(\"amount\"),\n",
    "        col(\"activityLog.details.order_id\").alias(\"order_id\"),\n",
    "        col(\"activityLog.details.restaurant_name\").alias(\"restaurant_name\"),\n",
    "        col(\"activityLog.details.role\").alias(\"role\"),\n",
    "        col(\"activityLog.details.success\").alias(\"success\"),\n",
    "        col(\"activityLog.details.total_amount\").alias(\"total_amount\"),\n",
    "        col(\"activityLog.details.items_count\").alias(\"items_count\"),\n",
    "        col(\"activityLog.timestamp\").alias(\"timestamp\"),\n",
    "        col(\"activityLog.user_id\").alias(\"user_id\")\n",
    "    )\n",
    "\n",
    "    return raw_data_bronze"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
